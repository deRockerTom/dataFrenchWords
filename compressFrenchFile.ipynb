{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0DIp97mlcwSAXjQjfgH8l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deRockerTom/dataFrenchWords/blob/main/compressFrenchFile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/deRockerTom/dataFrenchWords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scT0RXv3qF9z",
        "outputId": "bf3896e6-0102-424f-c575-98937acf40ea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dataFrenchWords'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 63 (delta 24), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (63/63), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textract"
      ],
      "metadata": {
        "id": "idoV1rZ_Jj0J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d097674f-4c3a-4da7-bd05-ee9f6ccebd85"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textract\n",
            "  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n",
            "Collecting extract-msg<=0.29.*\n",
            "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting argcomplete~=1.10.0\n",
            "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting SpeechRecognition~=3.8.1\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 151 kB/s \n",
            "\u001b[?25hCollecting beautifulsoup4~=4.8.0\n",
            "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 49.5 MB/s \n",
            "\u001b[?25hCollecting python-pptx~=0.6.18\n",
            "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 28.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from textract) (3.0.4)\n",
            "Collecting xlrd~=1.2.0\n",
            "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 37.2 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six==20191110\n",
            "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 8.9 MB/s \n",
            "\u001b[?25hCollecting six~=1.12.0\n",
            "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting docx2txt~=0.8\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4~=4.8.0->textract) (2.3.2.post1)\n",
            "Collecting compressed-rtf>=1.0.6\n",
            "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
            "Collecting tzlocal>=2.1\n",
            "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
            "Collecting olefile>=0.46\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 56.7 MB/s \n",
            "\u001b[?25hCollecting ebcdic>=1.1.1\n",
            "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 56.4 MB/s \n",
            "\u001b[?25hCollecting imapclient==2.1.0\n",
            "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract) (4.2.6)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract) (7.1.2)\n",
            "Collecting XlsxWriter>=0.5.7\n",
            "  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 48.8 MB/s \n",
            "\u001b[?25hCollecting backports.zoneinfo\n",
            "  Downloading backports.zoneinfo-0.2.1-cp37-cp37m-manylinux1_x86_64.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting pytz-deprecation-shim\n",
            "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tzdata\n",
            "  Downloading tzdata-2022.1-py2.py3-none-any.whl (339 kB)\n",
            "\u001b[K     |████████████████████████████████| 339 kB 47.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: docx2txt, compressed-rtf, olefile, python-pptx\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=89bab0b6fc8ce5a0ce5ca9f101edffe73fd22dcb51f69ef0a0b7247e4a66a0b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6204 sha256=052b7abfe4558d8632a5095ed796219aaaec5d80538131e9b3c13b82610a6bf1\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/33/88/88ceee84d1b74b391c086bc594d3fcf80800decfbd6e1ff565\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35432 sha256=cf62d8e557ccd706b41a667c387b9fa96dd07796524d94f504e61f5ae8189b95\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/53/e6/37d90ccb3ad1a3ca98d2b17107e9fda401a7c541ea1eb6a65a\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470951 sha256=4398b7139664b4d2f82de65e323a514f2d1cd12daf437eb0bf6bf41bb54ed594\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/ab/f4/52560d0d4bd4055e9261c6df6e51c7b56c2b23cca3dee811a3\n",
            "Successfully built docx2txt compressed-rtf olefile python-pptx\n",
            "Installing collected packages: tzdata, backports.zoneinfo, six, pytz-deprecation-shim, XlsxWriter, tzlocal, pycryptodome, olefile, imapclient, ebcdic, compressed-rtf, xlrd, SpeechRecognition, python-pptx, pdfminer.six, extract-msg, docx2txt, beautifulsoup4, argcomplete, textract\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: tzlocal\n",
            "    Found existing installation: tzlocal 1.5.1\n",
            "    Uninstalling tzlocal-1.5.1:\n",
            "      Successfully uninstalled tzlocal-1.5.1\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.12.0 which is incompatible.\n",
            "google-api-python-client 1.12.11 requires six<2dev,>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "google-api-core 1.31.6 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed SpeechRecognition-3.8.1 XlsxWriter-3.0.3 argcomplete-1.10.3 backports.zoneinfo-0.2.1 beautifulsoup4-4.8.2 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.14.1 python-pptx-0.6.21 pytz-deprecation-shim-0.1.0.post0 six-1.12.0 textract-1.6.5 tzdata-2022.1 tzlocal-4.2 xlrd-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install antiword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33bs4hiFJxhM",
        "outputId": "64497339-1b1f-4683-f985-071c030eb0ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  antiword\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 128 kB of archives.\n",
            "After this operation, 633 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 antiword amd64 0.37-11build1 [128 kB]\n",
            "Fetched 128 kB in 1s (133 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package antiword.\n",
            "(Reading database ... 155639 files and directories currently installed.)\n",
            "Preparing to unpack .../antiword_0.37-11build1_amd64.deb ...\n",
            "Unpacking antiword (0.37-11build1) ...\n",
            "Setting up antiword (0.37-11build1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textract\n",
        "text = textract.process(\"dataFrenchWords/maupassant_bel_ami_illustre.doc\")\n",
        "text = text.decode(\"utf-8\")\n",
        "text = text.replace('’', '\\'').replace('–', '-').replace('…', '...').replace('‘', '\\'').replace('€', 'euros').replace('[pic]', '')"
      ],
      "metadata": {
        "id": "m-h39iUgJbvv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionnary with text with 256 most frequent substrings of n char\n",
        "\n",
        "def createDic(string, n):\n",
        "  dic = {}\n",
        "  for i in range(len(string) - n):\n",
        "    dic[string[i:i + n]] = string.count(string[i:i + n])\n",
        "  # dic = dict(sorted(dic.items(), key=lambda item: item[1], reverse=True))\n",
        "  dic = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1], reverse=True)}\n",
        "  dic = {k: dic[k] for k in list(dic)[:256]} # In order to code the dictionnary on only 1 other bytes with most frequent words\n",
        "  return dic\n",
        "dicHugo3 = createDic(text, 3)\n",
        "print(dicHugo3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsUP8YnEOH--",
        "outputId": "76330fcf-d0d3-4862-b93c-2c43efb24a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'   ': 6274, ' de': 5924, 'e  ': 5540, 'es ': 5000, '\\n  ': 4644, '\\n\\n ': 4578, '\\n\\n\\n': 4539, 'it ': 4254, 'ait': 4143, 'de ': 3876, 'le ': 3797, 's  ': 3569, ' le': 3502, 'ent': 3467, 'nt ': 3345, 't  ': 3332, ' qu': 2994, '  d': 2981, 'lle': 2693, 'ne ': 2653, 'e, ': 2577, ',  ': 2522, 'ant': 2461, ' et': 2456, 'et ': 2455, ' la': 2347, '  l': 2330, ' pa': 2261, ' un': 2235, 'la ': 2190, 'our': 2106, ' se': 2085, 'que': 2084, 're ': 2076, ' co': 2051, 's, ': 1932, 'e d': 1913, 'ais': 1902, 'les': 1900, 'is ': 1900, '  s': 1847, 'il ': 1847, 'on ': 1830, 'ur ': 1784, '  p': 1772, '.\\n\\n': 1763, ' «\\xa0': 1727, ' so': 1715, ' en': 1693, 'er ': 1689, 'ous': 1664, 'ns ': 1641, 'us ': 1641, 'ien': 1636, ' à ': 1628, 'e s': 1625, '  c': 1584, 'une': 1551, 'en ': 1543, ' po': 1535, 'un ': 1532, 'e l': 1477, ' il': 1475, '  e': 1465, 'mme': 1460, 'n  ': 1459, 'te ': 1445, 'ue ': 1433, 'me ': 1421, ' re': 1418, 'tre': 1401, '\\xa0»\\n': 1392, '»\\n\\n': 1382, 't d': 1379, '  «': 1379, 't, ': 1372, 'eur': 1355, 'ui ': 1345, ' Il': 1338, ' vo': 1335, 'se ': 1332, 's d': 1332, 'par': 1325, 'r  ': 1324, 'res': 1308, 'des': 1306, ' ma': 1284, \" l'\": 1282, 'ell': 1273, 'tou': 1270, ' to': 1267, 'e p': 1264, ' sa': 1259, \" d'\": 1245, '  a': 1230, 'Il ': 1229, ' ce': 1225, 'ans': 1217, ' av': 1213, 'omm': 1188, 'men': 1182, 'tai': 1175, 'est': 1173, '.\\xa0»': 1171, ' mo': 1152, 'rai': 1132, '\\xa0:\\n': 1131, ' ch': 1128, 'out': 1110, 'che': 1104, 'e c': 1092, 'dan': 1091, ':\\n\\n': 1074, ' au': 1050, 'ut ': 1043, 'pou': 1037, 'a  ': 1036, 'vai': 1033, 't l': 1030, 'son': 1025, 'com': 1010, 's l': 1004, ' su': 988, ' pe': 986, ' pr': 982, 'qui': 981, \"qu'\": 971, 'ce ': 962, ', e': 960, '  m': 959, 'pas': 958, 'eux': 957, 'nte': 945, 'mai': 939, 'vou': 931, 'ren': 910, '  I': 902, ' ne': 897, 'ux ': 895, '.  ': 892, 'end': 891, ' fa': 890, 'ire': 864, 'con': 860, 'ave': 857, '  q': 856, '  t': 855, ' tr': 854, ' da': 854, 'ill': 845, ' lu': 839, 't p': 837, 'e m': 829, 'lui': 827, 'eme': 822, ' je': 813, 'uis': 809, 'ain': 808, 'ouv': 800, '  f': 796, 'ran': 795, 'ons': 793, 'ava': 790, 't s': 788, 'e. ': 780, '  E': 774, 'es,': 772, 'and': 768, 'lai': 766, 'e t': 760, 'l  ': 759, 's p': 755, 'sse': 751, 'éta': 750, 'ion': 748, 'e e': 746, 'e v': 746, 'cha': 745, 'as ': 744, 'r, ': 739, \" s'\": 737, 'ort': 732, 'ont': 728, ' di': 727, 'ir ': 724, 'sai': 723, 'tte': 716, 'aie': 714, 'e f': 711, 'ure': 708, 'e r': 704, 'ère': 704, 'rs ': 704, 'onn': 700, 'ten': 699, '  v': 694, 's s': 691, 'sur': 682, '  r': 679, 'r l': 678, 'ter': 673, 'Ell': 672, ' pl': 667, ' du': 661, 'int': 660, 'fai': 659, ', d': 651, 'i  ': 645, ' El': 644, 'ier': 641, 'sa ': 639, \"'un\": 635, 'cou': 635, 'ser': 626, 'ond': 625, 'jou': 624, 'du ': 623, 'ett': 621, 'tes': 620, 's c': 619, 'vec': 618, 'san': 616, '  u': 615, ' vi': 615, 'iss': 612, 'air': 611, 's e': 610, \"'es\": 610, 'ses': 608, 's a': 607, 'u  ': 607, 'au ': 605, 'je ': 601, 'voi': 601, ' no': 601, 'ssa': 599, ' dé': 599, '...': 597, 'e.\\n': 596, 'urs': 595, 'ass': 593, ' do': 591, 't e': 590, 'ec ': 589, \"l'a\": 589, 'ver': 588, 'sou': 587, 'mon': 584, 'aut': 584, 'n, ': 580, ' el': 580, 'st ': 576, 'dit': 571, '  i': 568, 'tro': 567, 'ieu': 563}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def createDicMax(string, n):\n",
        "  dic = {}\n",
        "  for k in range(2,n):\n",
        "    for i in range(len(string) - k):\n",
        "      dic[string[i:i + k]] = int((1.5 * string.count(string[i:i + k])) // k) # In order to favorise a bit bigger words\n",
        "  dic = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1], reverse=True)}\n",
        "  dic = {k: dic[k] for k in list(dic)[:256]} # In order to code the dictionnary on only 1 other bytes with most frequent words\n",
        "  return dic\n",
        "dicHugoMax4 = createDicMax(text, 4)"
      ],
      "metadata": {
        "id": "qkP7bb-kc0Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicHugoMax50 = createDicMax(text, 50)"
      ],
      "metadata": {
        "id": "xQAUzjGg0AYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicByHugo = dicHugo3\n",
        "dicByHugoMax = dicHugoMax4"
      ],
      "metadata": {
        "id": "2aO1zKRMWRKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in dicByHugoMax:\n",
        "  dicByHugoMax[k] = int(dicByHugoMax[k])\n",
        "for k in dicHugoMax50:\n",
        "  dicHugoMax50[k] = int(dicHugoMax50[k])\n",
        "for k in dicHugoMax10:\n",
        "  dicHugoMax10[k] = int(dicHugoMax10[k])"
      ],
      "metadata": {
        "id": "0H4He2g0Xao6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert our dicts to files\n",
        "\n",
        "\n",
        "with open('dicByHugo', 'w') as f:\n",
        "  for key in dicByHugo.keys():\n",
        "    f.write(\"%sក%sខ\" % (key, dicByHugo[key]))\n",
        "\n",
        "\n",
        "with open('dicByHugoMax', 'w') as f:\n",
        "  for key in dicByHugoMax.keys():\n",
        "    f.write(\"%sក%sខ\" % (key, dicByHugoMax[key]))\n",
        "\n",
        "with open('dicByHugoMax10', 'w') as f:\n",
        "  for key in dicHugoMax10.keys():\n",
        "    f.write(\"%sក%sខ\" % (key, dicHugoMax10[key]))\n",
        "\n",
        "with open('dicByHugoMax50', 'w') as f:\n",
        "  for key in dicHugoMax50.keys():\n",
        "    f.write(\"%sក%sខ\" % (key, dicHugoMax50[key]))\n"
      ],
      "metadata": {
        "id": "juyIVewNmqbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get dict with file\n",
        "import os\n",
        "\n",
        "def getDictWithFile(file):\n",
        "  with open(file, 'r') as f:\n",
        "    dic = {}\n",
        "    key = \"\"\n",
        "    value = \"\"\n",
        "    isKey = True\n",
        "    for l in f.readlines():\n",
        "      for c in l:\n",
        "        if c == 'ក':\n",
        "          isKey = False\n",
        "        elif c == 'ខ':\n",
        "          isKey = True\n",
        "          dic[key] = int(value)\n",
        "          key = \"\"\n",
        "          value = \"\"\n",
        "        else:\n",
        "          if isKey:\n",
        "            key = key + c\n",
        "          else:\n",
        "            value = value + c\n",
        "    value = value + \"\\n\"\n",
        "  return dic\n",
        "\n",
        "dicByHugo = getDictWithFile('dataFrenchWords/dicByHugo')\n",
        "dicByHugoMax = getDictWithFile('dataFrenchWords/dicByHugoMax')\n",
        "dictByHugoMax10 = getDictWithFile('dataFrenchWords/dicByHugoMax10')\n",
        "dictByHugoMax50 = getDictWithFile('dataFrenchWords/dicByHugoMax50')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D-79WIkptQUQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convertToBinary(number):\n",
        "  binary = ''\n",
        "  while number > 0:\n",
        "    binary = str(number % 2) + binary\n",
        "    number = number // 2\n",
        "  return binary\n",
        "def convertToNineBits(bits):\n",
        "  n = len(bits)\n",
        "  if n < 9:\n",
        "    k = 9 - n\n",
        "    return str('0') * k + bits\n",
        "  elif n == 9:\n",
        "    return bits\n",
        "  else:\n",
        "    print(\"Attention : un des encodages est trop grand (>9)\")\n",
        "    print(bits)\n",
        "\n",
        "convertToNineBits(convertToBinary(255))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3osK_tKk8uSu",
        "outputId": "d326bde1-034d-40df-932d-99d742cbe624"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'011111111'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# open csv\n",
        "dic = {}\n",
        "with open('dataFrenchWords/french-word-list-verbs.csv', 'r') as csvfile:\n",
        "  reader = csv.reader(csvfile)\n",
        "  #drop first 3 lines\n",
        "  next(reader)\n",
        "  next(reader)\n",
        "  next(reader)\n",
        "  #create dictionary\n",
        "  for row in reader:\n",
        "    if row[1] in dic:\n",
        "      dic[row[1]] += int(row[2])\n",
        "    else:\n",
        "      dic[row[1]] = int(row[2])\n",
        "  csvfile.close()\n",
        "\n",
        "with open('dataFrenchWords/french-word-list-adjectives.csv', 'r') as csvfile:\n",
        "  reader = csv.reader(csvfile)\n",
        "  #drop first 3 lines\n",
        "  next(reader)\n",
        "  next(reader)\n",
        "  next(reader)\n",
        "  #create dictionary\n",
        "  for row in reader:\n",
        "    if row[1] in dic:\n",
        "      dic[row[1]] += int(row[2])\n",
        "    else:\n",
        "      dic[row[1]] = int(row[2])\n",
        "  csvfile.close()\n",
        "\n",
        "with open('dataFrenchWords/french-word-list-nouns.csv', 'r') as csvfile:\n",
        "  reader = csv.reader(csvfile)\n",
        "  #drop first 3 lines\n",
        "  next(reader)\n",
        "  next(reader)\n",
        "  next(reader)\n",
        "  #create dictionary\n",
        "  for row in reader:\n",
        "    if row[1] in dic:\n",
        "      dic[row[1]] += int(row[2])\n",
        "    else:\n",
        "      dic[row[1]] = int(row[2])\n",
        "  csvfile.close()\n",
        "\n",
        "# Ponctuation :\n",
        "\n",
        "dic[', '] = 150000\n",
        "dic['. '] = 150000\n",
        "\n",
        "dic = dict(sorted(dic.items(), key=lambda item: item[1], reverse=True))\n",
        "dic = {k: dic[k] for k in list(dic)[:256]} # In order to code the dictionnary on only 2 other bytes with most frequent words\n",
        "offset = 256\n",
        "i = 0\n",
        "for key in dic:\n",
        "  dic[key] = convertToNineBits(convertToBinary(offset + i))\n",
        "  offset += 1\n",
        "dic2 = {}\n",
        "offset = 256\n",
        "for key in dicByHugo:\n",
        "  dic2[key] = convertToNineBits(convertToBinary(offset + i))\n",
        "  offset += 1\n",
        "dic3 = {}\n",
        "offset = 256\n",
        "for key in dicByHugoMax:\n",
        "  dic3[key] = convertToNineBits(convertToBinary(offset + i))\n",
        "  offset += 1\n",
        "dic4 = {}\n",
        "offset = 256\n",
        "for key in dictByHugoMax10:\n",
        "  dic4[key] = convertToNineBits(convertToBinary(offset + i))\n",
        "  offset += 1\n",
        "dic5 = {}\n",
        "offset = 256\n",
        "for key in dictByHugoMax50:\n",
        "  dic5[key] = convertToNineBits(convertToBinary(offset + i))\n",
        "  offset += 1\n",
        "\n",
        "print(dic5)\n",
        "\n",
        "reverted_dic = {v: k for k, v in dic.items()}\n",
        "reverted_dic2 = {v: k for k, v in dic2.items()}\n",
        "reverted_dic3 = {v: k for k, v in dic3.items()}\n",
        "reverted_dic4 = {v: k for k, v in dic4.items()}\n",
        "reverted_dic5 = {v: k for k, v in dic5.items()}\n",
        "\n",
        "print(reverted_dic5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awJCxj_ArQG9",
        "outputId": "edd20bfd-5045-4e8a-d6cc-49eaaff335fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'  ': '100000000', 'e ': '100000001', 's ': '100000010', 't ': '100000011', ' d': '100000100', ', ': '100000101', 'ai': '100000110', 'es': '100000111', ' l': '100001000', 'le': '100001001', 'en': '100001010', 're': '100001011', 'ou': '100001100', 'de': '100001101', ' s': '100001110', 'nt': '100001111', 'it': '100010000', ' p': '100010001', 'on': '100010010', ' c': '100010011', 'an': '100010100', 'n ': '100010101', ' e': '100010110', 'ur': '100010111', 'te': '100011000', 'er': '100011001', 'is': '100011010', 'r ': '100011011', '\\n ': '100011100', ' a': '100011101', '\\n\\n': '100011110', 'a ': '100011111', 'qu': '100100000', '   ': '100100001', 'se': '100100010', 'ne': '100100011', 'et': '100100100', ' m': '100100101', 'me': '100100110', 'la': '100100111', ' de': '100101000', 'ie': '100101001', 'il': '100101010', 'e  ': '100101011', 'eu': '100101100', ' t': '100101101', 'ra': '100101110', 'ar': '100101111', 'in': '100110000', 'll': '100110001', 'ui': '100110010', 'l ': '100110011', 'es ': '100110100', 'un': '100110101', '. ': '100110110', '\\n  ': '100110111', ' f': '100111000', 'us': '100111001', '\\n\\n ': '100111010', '\\n\\n\\n': '100111011', 'co': '100111100', ' q': '100111101', ' r': '100111110', ' v': '100111111', 'tr': '101000000', 'pa': '101000001', 'ns': '101000010', 'ue': '101000011', 'it ': '101000100', 'oi': '101000101', 'ait': '101000110', 'e,': '101000111', '    ': '101001000', 'ce': '101001001', 'sa': '101001010', 'de ': '101001011', 've': '101001100', 'le ': '101001101', 'i ': '101001110', 'ta': '101001111', 'ut': '101010000', 'ri': '101010001', 'au': '101010010', 'u ': '101010011', 'ch': '101010100', 'em': '101010101', 'nd': '101010110', 's  ': '101010111', 'ti': '101011000', 'ir': '101011001', ' le': '101011010', '\\n   ': '101011011', 'ent': '101011100', 'ma': '101011101', 'ro': '101011110', '\\n\\n  ': '101011111', 'so': '101100000', 'po': '101100001', '\\n\\n\\n ': '101100010', ' u': '101100011', 'nt ': '101100100', 'el': '101100101', 't  ': '101100110', ' n': '101100111', 'or': '101101000', 'ss': '101101001', ' i': '101101010', ' b': '101101011', 's,': '101101100', ' qu': '101101101', '  d': '101101110', '.\\n': '101101111', 'om': '101110000', \"'a\": '101110001', 'av': '101110010', 'as': '101110011', 'vo': '101110100', 'va': '101110101', '\\n    ': '101110110', 'à ': '101110111', 'st': '101111000', '\\n\\n   ': '101111001', '\\n\\n\\n  ': '101111010', 'lle': '101111011', 'e.': '101111100', 'pr': '101111101', 'to': '101111110', '«\\xa0': '101111111', ' à': '110000000', ' j': '110000001', 'ne ': '110000010', 'da': '110000011', ' «': '110000100', '\\xa0»': '110000101', 'e, ': '110000110', ' de ': '110000111', ',  ': '110001000', 'al': '110001001', 'lu': '110001010', 'si': '110001011', 'ant': '110001100', ' et': '110001101', 'et ': '110001110', 'mm': '110001111', 'pe': '110010000', '\\xa0:': '110010001', 'ait ': '110010010', 'e\\n': '110010011', ' la': '110010100', '  l': '110010101', 'mo': '110010110', '\\n\\n    ': '110010111', '\\n\\n\\n   ': '110011000', ' pa': '110011001', ' un': '110011010', 'la ': '110011011', 't,': '110011100', 'di': '110011101', \"l'\": '110011110', 'he': '110011111', 'Il': '110100000', 'our': '110100001', '»\\n': '110100010', 'rt': '110100011', \"d'\": '110100100', 'que': '110100101', ' se': '110100110', 're ': '110100111', \"'e\": '110101000', ' I': '110101001', ' co': '110101010', 'na': '110101011', 'ux': '110101100', '\\n\\n\\n    ': '110101101', '.\\xa0': '110101110', 's, ': '110101111', 'e d': '110110000', 'ré': '110110001', 'nc': '110110010', 'rs': '110110011', 'ais': '110110100', 'les': '110110101', 'is ': '110110110', 'mi': '110110111', 's.': '110111000', '  s': '110111001', 'il ': '110111010', 'ge': '110111011', 'on ': '110111100', 'li': '110111101', 'su': '110111110', 'ét': '110111111', 'ur ': '111000000', 'fa': '111000001', '  p': '111000010', 'at': '111000011', '.\\n\\n': '111000100', ' g': '111000101', ' «\\xa0': '111000110', ' E': '111000111', ' so': '111001000', ':\\n': '111001001', ' en': '111001010', 'er ': '111001011', 'vi': '111001100', 'ous': '111001101', 'ns ': '111001110', 'us ': '111001111', 'ien': '111010000', ' à ': '111010001', 'e s': '111010010', 'ec': '111010011', ' et ': '111010100', 'ha': '111010101', 'tt': '111010110', 'e\\xa0': '111010111', 'x ': '111011000', 's\\n': '111011001', '  c': '111011010', 'ée': '111011011', ' é': '111011100', 'é ': '111011101', 'une': '111011110', 'en ': '111011111', ' po': '111100000', 'un ': '111100001', \"u'\": '111100010', 'pl': '111100011', 'e l': '111100100', ' il': '111100101', '  e': '111100110', 'mme': '111100111', 'n  ': '111101000', ' o': '111101001', ' la ': '111101010', 'no': '111101011', 'te ': '111101100', 'uv': '111101101', 'ue ': '111101110', 'nn': '111101111', 'me ': '111110000', ' re': '111110001', 'je': '111110010', 'tre': '111110011', 'bl': '111110100', '\\xa0»\\n': '111110101', 'du': '111110110', '»\\n\\n': '111110111', 't d': '111111000', '  «': '111111001', 't, ': '111111010', 'lo': '111111011', 'eur': '111111100', 'ui ': '111111101', ' Il': '111111110', ' vo': '111111111'}\n",
            "{'100000000': '  ', '100000001': 'e ', '100000010': 's ', '100000011': 't ', '100000100': ' d', '100000101': ', ', '100000110': 'ai', '100000111': 'es', '100001000': ' l', '100001001': 'le', '100001010': 'en', '100001011': 're', '100001100': 'ou', '100001101': 'de', '100001110': ' s', '100001111': 'nt', '100010000': 'it', '100010001': ' p', '100010010': 'on', '100010011': ' c', '100010100': 'an', '100010101': 'n ', '100010110': ' e', '100010111': 'ur', '100011000': 'te', '100011001': 'er', '100011010': 'is', '100011011': 'r ', '100011100': '\\n ', '100011101': ' a', '100011110': '\\n\\n', '100011111': 'a ', '100100000': 'qu', '100100001': '   ', '100100010': 'se', '100100011': 'ne', '100100100': 'et', '100100101': ' m', '100100110': 'me', '100100111': 'la', '100101000': ' de', '100101001': 'ie', '100101010': 'il', '100101011': 'e  ', '100101100': 'eu', '100101101': ' t', '100101110': 'ra', '100101111': 'ar', '100110000': 'in', '100110001': 'll', '100110010': 'ui', '100110011': 'l ', '100110100': 'es ', '100110101': 'un', '100110110': '. ', '100110111': '\\n  ', '100111000': ' f', '100111001': 'us', '100111010': '\\n\\n ', '100111011': '\\n\\n\\n', '100111100': 'co', '100111101': ' q', '100111110': ' r', '100111111': ' v', '101000000': 'tr', '101000001': 'pa', '101000010': 'ns', '101000011': 'ue', '101000100': 'it ', '101000101': 'oi', '101000110': 'ait', '101000111': 'e,', '101001000': '    ', '101001001': 'ce', '101001010': 'sa', '101001011': 'de ', '101001100': 've', '101001101': 'le ', '101001110': 'i ', '101001111': 'ta', '101010000': 'ut', '101010001': 'ri', '101010010': 'au', '101010011': 'u ', '101010100': 'ch', '101010101': 'em', '101010110': 'nd', '101010111': 's  ', '101011000': 'ti', '101011001': 'ir', '101011010': ' le', '101011011': '\\n   ', '101011100': 'ent', '101011101': 'ma', '101011110': 'ro', '101011111': '\\n\\n  ', '101100000': 'so', '101100001': 'po', '101100010': '\\n\\n\\n ', '101100011': ' u', '101100100': 'nt ', '101100101': 'el', '101100110': 't  ', '101100111': ' n', '101101000': 'or', '101101001': 'ss', '101101010': ' i', '101101011': ' b', '101101100': 's,', '101101101': ' qu', '101101110': '  d', '101101111': '.\\n', '101110000': 'om', '101110001': \"'a\", '101110010': 'av', '101110011': 'as', '101110100': 'vo', '101110101': 'va', '101110110': '\\n    ', '101110111': 'à ', '101111000': 'st', '101111001': '\\n\\n   ', '101111010': '\\n\\n\\n  ', '101111011': 'lle', '101111100': 'e.', '101111101': 'pr', '101111110': 'to', '101111111': '«\\xa0', '110000000': ' à', '110000001': ' j', '110000010': 'ne ', '110000011': 'da', '110000100': ' «', '110000101': '\\xa0»', '110000110': 'e, ', '110000111': ' de ', '110001000': ',  ', '110001001': 'al', '110001010': 'lu', '110001011': 'si', '110001100': 'ant', '110001101': ' et', '110001110': 'et ', '110001111': 'mm', '110010000': 'pe', '110010001': '\\xa0:', '110010010': 'ait ', '110010011': 'e\\n', '110010100': ' la', '110010101': '  l', '110010110': 'mo', '110010111': '\\n\\n    ', '110011000': '\\n\\n\\n   ', '110011001': ' pa', '110011010': ' un', '110011011': 'la ', '110011100': 't,', '110011101': 'di', '110011110': \"l'\", '110011111': 'he', '110100000': 'Il', '110100001': 'our', '110100010': '»\\n', '110100011': 'rt', '110100100': \"d'\", '110100101': 'que', '110100110': ' se', '110100111': 're ', '110101000': \"'e\", '110101001': ' I', '110101010': ' co', '110101011': 'na', '110101100': 'ux', '110101101': '\\n\\n\\n    ', '110101110': '.\\xa0', '110101111': 's, ', '110110000': 'e d', '110110001': 'ré', '110110010': 'nc', '110110011': 'rs', '110110100': 'ais', '110110101': 'les', '110110110': 'is ', '110110111': 'mi', '110111000': 's.', '110111001': '  s', '110111010': 'il ', '110111011': 'ge', '110111100': 'on ', '110111101': 'li', '110111110': 'su', '110111111': 'ét', '111000000': 'ur ', '111000001': 'fa', '111000010': '  p', '111000011': 'at', '111000100': '.\\n\\n', '111000101': ' g', '111000110': ' «\\xa0', '111000111': ' E', '111001000': ' so', '111001001': ':\\n', '111001010': ' en', '111001011': 'er ', '111001100': 'vi', '111001101': 'ous', '111001110': 'ns ', '111001111': 'us ', '111010000': 'ien', '111010001': ' à ', '111010010': 'e s', '111010011': 'ec', '111010100': ' et ', '111010101': 'ha', '111010110': 'tt', '111010111': 'e\\xa0', '111011000': 'x ', '111011001': 's\\n', '111011010': '  c', '111011011': 'ée', '111011100': ' é', '111011101': 'é ', '111011110': 'une', '111011111': 'en ', '111100000': ' po', '111100001': 'un ', '111100010': \"u'\", '111100011': 'pl', '111100100': 'e l', '111100101': ' il', '111100110': '  e', '111100111': 'mme', '111101000': 'n  ', '111101001': ' o', '111101010': ' la ', '111101011': 'no', '111101100': 'te ', '111101101': 'uv', '111101110': 'ue ', '111101111': 'nn', '111110000': 'me ', '111110001': ' re', '111110010': 'je', '111110011': 'tre', '111110100': 'bl', '111110101': '\\xa0»\\n', '111110110': 'du', '111110111': '»\\n\\n', '111111000': 't d', '111111001': '  «', '111111010': 't, ', '111111011': 'lo', '111111100': 'eur', '111111101': 'ui ', '111111110': ' Il', '111111111': ' vo'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class to build a tree defining all the possible  string in dic\n",
        "class SuffixTree():\n",
        "  class Node():\n",
        "    def __init__(self,char):\n",
        "      self.char = char\n",
        "      self.out = {}\n",
        "      self.isFinal = False\n",
        "    def __str__(self, level=0):\n",
        "      ret = \"  \" * level + str(self.char) + \"\\n\"\n",
        "      for c in self.out:\n",
        "        ret += self.out[c].__str__(level + 1)\n",
        "      return ret\n",
        "\n",
        "  def __init__(self, dic):\n",
        "    self.root = self.Node(None)\n",
        "    self.root.isFinal = True\n",
        "    for key in dic:\n",
        "      cursor = self.root\n",
        "      for c in key:\n",
        "        if c in cursor.out:\n",
        "          cursor = cursor.out[c]\n",
        "        else:\n",
        "          node = self.Node(c)\n",
        "          cursor.out[c] = node\n",
        "          cursor = node\n",
        "      cursor.isFinal = True\n",
        "  def longestPrefix(self, s):\n",
        "    cursor = self.root\n",
        "    word = ''\n",
        "    temp = ''\n",
        "    end = False\n",
        "    i = 0\n",
        "    length = len(s)\n",
        "    while not(end) and i < length:\n",
        "      if s[i] in cursor.out:\n",
        "        temp = temp + s[i]\n",
        "        cursor = cursor.out[s[i]]\n",
        "        if cursor.isFinal:\n",
        "          word = temp\n",
        "        i += 1\n",
        "      else:\n",
        "        end = True\n",
        "    return word\n",
        "  def __str__(self):\n",
        "    return f'{self.root}'\n",
        "\n",
        "s = SuffixTree({'ab' : 1, 'abc': 2, 'coucou' : 5, 'aba' : 4, 'aaa' : 8})\n",
        "print(s)\n",
        "s.longestPrefix('abdc')\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "ND_fSFhFq51O",
        "outputId": "312f355e-7cfa-4d97-dbeb-14159ee92069"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "  a\n",
            "    b\n",
            "      c\n",
            "      a\n",
            "    a\n",
            "      a\n",
            "  c\n",
            "    o\n",
            "      u\n",
            "        c\n",
            "          o\n",
            "            u\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ab'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree = SuffixTree(dic)\n",
        "tree2 = SuffixTree(dic2)\n",
        "tree3 = SuffixTree(dic3)\n",
        "tree4 = SuffixTree(dic4)\n",
        "tree5 = SuffixTree(dic5)"
      ],
      "metadata": {
        "id": "FgOeftRxAILs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First implementation with first dictionnary\n",
        "\n",
        "def compress(string, tree, dic):\n",
        "  i = 0\n",
        "  ret = ''\n",
        "  while i<len(string):\n",
        "    temp = tree.longestPrefix(string[i:])\n",
        "    n = len(temp)\n",
        "    if n == 0:\n",
        "      bit = convertToNineBits(convertToBinary(ord(string[i])))\n",
        "      ret += bit\n",
        "      i += 1\n",
        "    else:\n",
        "      bit = dic[temp]\n",
        "      ret += bit\n",
        "      i += n\n",
        "  return ret\n",
        "\n",
        "\n",
        "\n",
        "def decompress(string, dic):\n",
        "  ret = ''\n",
        "  for i in range(0, len(string) - 1, 9):\n",
        "    if int(string[i : i + 9], 2) > 255:\n",
        "      ret += dic[string[i : i + 9]]\n",
        "    else:\n",
        "      ret += chr(int(string[i : i + 9], 2))\n",
        "  return ret"
      ],
      "metadata": {
        "id": "d22Anv76pQBY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed = compress(text, tree, dic)\n",
        "\n",
        "decompressed = decompress(compressed, reverted_dic)\n",
        "\n",
        "\n",
        "print(f'Le fichier avant décompression faisait {len(text) * 8} octets et celui compressé fait {len(compressed)} octets')\n",
        "print(f'Le taux de compression est donc de {len(text) * 8 / len(compressed)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y394yPYxZrGi",
        "outputId": "19b7e47c-3d6b-4438-c662-3fbc90651d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier avant décompression faisait 5445800 octets et celui compressé fait 5363739 octets\n",
            "Le taux de compression est donc de 1.0152992157150078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compressed2 = compress(text, tree2, dic2)\n",
        "\n",
        "decompressed2 = decompress(compressed2, reverted_dic2)\n",
        "\n",
        "\n",
        "print(f'Le fichier avant décompression faisait {len(text) * 8} octets et celui compressé fait {len(compressed2)} octets')\n",
        "print(f'Le taux de compression est donc de {len(text) * 8 / len(compressed2)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wntOWF28ZyVg",
        "outputId": "35d716c0-dc18-470e-bdf3-dd97c9b9bf56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier avant décompression faisait 5445800 octets et celui compressé fait 3425643 octets\n",
            "Le taux de compression est donc de 1.5897161496396444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compressed3 = compress(text, tree3, dic3)\n",
        "\n",
        "decompressed3 = decompress(compressed3, reverted_dic3)\n",
        "\n",
        "\n",
        "print(f'Le fichier avant décompression faisait {len(text) * 8} octets et celui compressé fait {len(compressed3)} octets')\n",
        "print(f'Le taux de compression est donc de {len(text) * 8 / len(compressed3)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_g1-f2Yk27Z",
        "outputId": "2c99ca52-53db-4146-e830-486ac9c789bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier avant décompression faisait 5445800 octets et celui compressé fait 3055878 octets\n",
            "Le taux de compression est donc de 1.7820737607980424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compressed4 = compress(text, tree4, dic4)\n",
        "\n",
        "decompressed4 = decompress(compressed4, reverted_dic4)\n",
        "\n",
        "\n",
        "print(f'Le fichier avant décompression faisait {len(text) * 8} octets et celui compressé fait {len(compressed4)} octets')\n",
        "print(f'Le taux de compression est donc de {len(text) * 8 / len(compressed4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4183dc30-95d2-4d2e-c341-355a03b7589d",
        "id": "q-cJTpd9Rdn5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier avant décompression faisait 5445800 octets et celui compressé fait 3034512 octets\n",
            "Le taux de compression est donc de 1.7946213427397881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compressed5 = compress(text, tree5, dic5)\n",
        "\n",
        "decompressed5 = decompress(compressed5, reverted_dic5)\n",
        "\n",
        "\n",
        "print(f'Le fichier avant décompression faisait {len(text) * 8} octets et celui compressé fait {len(compressed5)} octets')\n",
        "print(f'Le taux de compression est donc de {len(text) * 8 / len(compressed5)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d641fb6-e1ed-4df7-ff2b-feca6c76ef59",
        "id": "M4mWLXmVReFY"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier avant décompression faisait 5445800 octets et celui compressé fait 3034512 octets\n",
            "Le taux de compression est donc de 1.7946213427397881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test du dictionnaire sur un autre livre, ici le premier tome du livre \"Les misérables\"**"
      ],
      "metadata": {
        "id": "njuNcCPPTnWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textract\n",
        "text2 = textract.process(\"dataFrenchWords/hugo_les_miserables_fantine_source.doc\")\n",
        "text2 = text2.decode(\"utf-8\")\n",
        "text2 = text2.replace('’', '\\'').replace('–', '-').replace('…', '...').replace('‘', '\\'').replace('€', 'euros').replace('[pic]', '')"
      ],
      "metadata": {
        "id": "d3sqDrKnUFrb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed6 = compress(text2, tree5, dic5)\n",
        "\n",
        "decompressed6 = decompress(compressed6, reverted_dic5)\n",
        "\n",
        "\n",
        "print(f'Le fichier avant décompression faisait {len(text2) * 8} octets et celui compressé fait {len(compressed6)} octets')\n",
        "print(f'Le taux de compression est donc de {len(text2) * 8 / len(compressed6)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItGmxIkvUMIn",
        "outputId": "3c6f5fcd-eecb-4703-d9a2-041d8b9446c9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier avant décompression faisait 6131592 octets et celui compressé fait 3502737 octets\n",
            "Le taux de compression est donc de 1.7505145262119308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('miserables.txt', 'w') as f:\n",
        "  f.write(text2)"
      ],
      "metadata": {
        "id": "7ltPOdqEZwHY"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}