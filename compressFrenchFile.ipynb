{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPc4VrjfEyFSl9uO+7y89S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deRockerTom/dataFrenchWords/blob/main/compressFrenchFile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/deRockerTom/dataFrenchWords\n",
        "!pip install textract\n",
        "!sudo apt-get install antiword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "scT0RXv3qF9z",
        "outputId": "bc4c0b10-e687-43c6-a52c-e8f33e2b0332"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dataFrenchWords'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 81 (delta 0), reused 0 (delta 0), pack-reused 78\u001b[K\n",
            "Unpacking objects: 100% (81/81), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textract\n",
            "  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n",
            "Collecting extract-msg<=0.29.*\n",
            "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting SpeechRecognition~=3.8.1\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 1.6 MB/s \n",
            "\u001b[?25hCollecting docx2txt~=0.8\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "Collecting xlrd~=1.2.0\n",
            "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 60.9 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six==20191110\n",
            "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 19.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from textract) (3.0.4)\n",
            "Collecting six~=1.12.0\n",
            "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting python-pptx~=0.6.18\n",
            "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 52.1 MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4~=4.8.0\n",
            "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 65.3 MB/s \n",
            "\u001b[?25hCollecting argcomplete~=1.10.0\n",
            "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 51.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4~=4.8.0->textract) (2.3.2.post1)\n",
            "Collecting compressed-rtf>=1.0.6\n",
            "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
            "Collecting imapclient==2.1.0\n",
            "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting olefile>=0.46\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 86.2 MB/s \n",
            "\u001b[?25hCollecting tzlocal>=2.1\n",
            "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
            "Collecting ebcdic>=1.1.1\n",
            "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 61.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract) (4.2.6)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract) (7.1.2)\n",
            "Collecting XlsxWriter>=0.5.7\n",
            "  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 65.4 MB/s \n",
            "\u001b[?25hCollecting pytz-deprecation-shim\n",
            "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting backports.zoneinfo\n",
            "  Downloading backports.zoneinfo-0.2.1-cp37-cp37m-manylinux1_x86_64.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 9.8 MB/s \n",
            "\u001b[?25hCollecting tzdata\n",
            "  Downloading tzdata-2022.1-py2.py3-none-any.whl (339 kB)\n",
            "\u001b[K     |████████████████████████████████| 339 kB 61.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: docx2txt, compressed-rtf, olefile, python-pptx\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=4fe9b0229ba89f0900113284bcc434fe1293f4519179c4a37c50699c28f1afdb\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6204 sha256=18b6bcf7029cb709cc98667b0852f2658cd252154ae6f89ac431c700ae83674a\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/33/88/88ceee84d1b74b391c086bc594d3fcf80800decfbd6e1ff565\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35432 sha256=e2cd7728fa4091896c7fa2378a42e5ad6a4b9c5dbf80acb424f7a3f2c2a3bc45\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/53/e6/37d90ccb3ad1a3ca98d2b17107e9fda401a7c541ea1eb6a65a\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470951 sha256=9b5f84c02d28c07892055c729a39ac9c65b0abed6574939047153f7977747088\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/ab/f4/52560d0d4bd4055e9261c6df6e51c7b56c2b23cca3dee811a3\n",
            "Successfully built docx2txt compressed-rtf olefile python-pptx\n",
            "Installing collected packages: tzdata, backports.zoneinfo, six, pytz-deprecation-shim, XlsxWriter, tzlocal, pycryptodome, olefile, imapclient, ebcdic, compressed-rtf, xlrd, SpeechRecognition, python-pptx, pdfminer.six, extract-msg, docx2txt, beautifulsoup4, argcomplete, textract\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: tzlocal\n",
            "    Found existing installation: tzlocal 1.5.1\n",
            "    Uninstalling tzlocal-1.5.1:\n",
            "      Successfully uninstalled tzlocal-1.5.1\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.12.0 which is incompatible.\n",
            "google-api-python-client 1.12.11 requires six<2dev,>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "google-api-core 1.31.6 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed SpeechRecognition-3.8.1 XlsxWriter-3.0.3 argcomplete-1.10.3 backports.zoneinfo-0.2.1 beautifulsoup4-4.8.2 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.14.1 python-pptx-0.6.21 pytz-deprecation-shim-0.1.0.post0 six-1.12.0 textract-1.6.5 tzdata-2022.1 tzlocal-4.2 xlrd-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  antiword\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 128 kB of archives.\n",
            "After this operation, 633 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 antiword amd64 0.37-11build1 [128 kB]\n",
            "Fetched 128 kB in 1s (218 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package antiword.\n",
            "(Reading database ... 155639 files and directories currently installed.)\n",
            "Preparing to unpack .../antiword_0.37-11build1_amd64.deb ...\n",
            "Unpacking antiword (0.37-11build1) ...\n",
            "Setting up antiword (0.37-11build1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textract\n",
        "text = textract.process(\"dataFrenchWords/maupassant_bel_ami_illustre.doc\")\n",
        "text = text.decode(\"utf-8\")\n",
        "text = text.replace('’', '\\'').replace('–', '-').replace('…', '...').replace('‘', '\\'').replace('€', 'euros').replace('[pic]', '')"
      ],
      "metadata": {
        "id": "m-h39iUgJbvv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get dict with file\n",
        "import os\n",
        "\n",
        "def getDictWithFile(file):\n",
        "  with open(file, 'r') as f:\n",
        "    dic = {}\n",
        "    key = \"\"\n",
        "    value = \"\"\n",
        "    isKey = True\n",
        "    for l in f.readlines():\n",
        "      for c in l:\n",
        "        if c == 'ក':\n",
        "          isKey = False\n",
        "        elif c == 'ខ':\n",
        "          isKey = True\n",
        "          dic[key] = int(value)\n",
        "          key = \"\"\n",
        "          value = \"\"\n",
        "        else:\n",
        "          if isKey:\n",
        "            key = key + c\n",
        "          else:\n",
        "            value = value + c\n",
        "    value = value + \"\\n\"\n",
        "  return dic\n",
        "\n",
        "dicByHugo = getDictWithFile('dataFrenchWords/dicByHugo')\n",
        "dicByHugoMax = getDictWithFile('dataFrenchWords/dicByHugoMax')\n",
        "dictByHugoMax10 = getDictWithFile('dataFrenchWords/dicByHugoMax10')\n",
        "dictByHugoMax50 = getDictWithFile('dataFrenchWords/dicByHugoMax50')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D-79WIkptQUQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convertToBinary(number):\n",
        "  binary = ''\n",
        "  while number > 0:\n",
        "    binary = str(number % 2) + binary\n",
        "    number = number // 2\n",
        "  return binary\n",
        "def convertToNineBits(bits):\n",
        "  n = len(bits)\n",
        "  if n < 9:\n",
        "    k = 9 - n\n",
        "    return str('0') * k + bits\n",
        "  elif n == 9:\n",
        "    return bits\n",
        "  else:\n",
        "    print(\"Attention : un des encodages est trop grand (>9)\")\n",
        "    print(bits)\n",
        "\n",
        "convertToNineBits(convertToBinary(255))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3osK_tKk8uSu",
        "outputId": "6adc75b2-07a5-4634-bb94-0f0d48e3b1eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'011111111'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# open csv\n",
        "dic = {}\n",
        "with open('dataFrenchWords/french-word-list-verbs.csv', 'r') as csvfile:\n",
        "  reader = csv.reader(csvfile)\n",
        "  #drop first 3 lines\n",
        "  next(reader)\n",
        "  next(reader)\n",
        "  next(reader)\n",
        "  #create dictionary\n",
        "  for row in reader:\n",
        "    if row[1] in dic:\n",
        "      dic[row[1]] += int(row[2])\n",
        "    else:\n",
        "      dic[row[1]] = int(row[2])\n",
        "  csvfile.close()\n",
        "\n",
        "with open('dataFrenchWords/french-word-list-adjectives.csv', 'r') as csvfile:\n",
        "  reader = csv.reader(csvfile)\n",
        "  #drop first 3 lines\n",
        "  next(reader)\n",
        "  next(reader)\n",
        "  next(reader)\n",
        "  #create dictionary\n",
        "  for row in reader:\n",
        "    if row[1] in dic:\n",
        "      dic[row[1]] += int(row[2])\n",
        "    else:\n",
        "      dic[row[1]] = int(row[2])\n",
        "  csvfile.close()\n",
        "\n",
        "with open('dataFrenchWords/french-word-list-nouns.csv', 'r') as csvfile:\n",
        "  reader = csv.reader(csvfile)\n",
        "  #drop first 3 lines\n",
        "  next(reader)\n",
        "  next(reader)\n",
        "  next(reader)\n",
        "  #create dictionary\n",
        "  for row in reader:\n",
        "    if row[1] in dic:\n",
        "      dic[row[1]] += int(row[2])\n",
        "    else:\n",
        "      dic[row[1]] = int(row[2])\n",
        "  csvfile.close()\n",
        "\n",
        "# Ponctuation :\n",
        "\n",
        "dic[', '] = 150000\n",
        "dic['. '] = 150000\n",
        "\n",
        "dic = dict(sorted(dic.items(), key=lambda item: item[1], reverse=True))\n",
        "dic = {k: dic[k] for k in list(dic)[:256]} # In order to code the dictionnary on only 2 other bytes with most frequent words\n",
        "offset = 256\n",
        "i = 0\n",
        "for key in dic:\n",
        "  dic[key] = convertToNineBits(convertToBinary(offset + i))\n",
        "  offset += 1\n",
        "dic2 = {}\n",
        "offset = 256\n",
        "for key in dicByHugo:\n",
        "  dic2[key] = convertToNineBits(convertToBinary(offset + i))\n",
        "  offset += 1\n",
        "dic3 = {}\n",
        "offset = 256\n",
        "for key in dicByHugoMax:\n",
        "  dic3[key] = convertToNineBits(convertToBinary(offset + i))\n",
        "  offset += 1\n",
        "dic4 = {}\n",
        "offset = 256\n",
        "for key in dictByHugoMax10:\n",
        "  dic4[key] = convertToNineBits(convertToBinary(offset + i))\n",
        "  offset += 1\n",
        "dic5 = {}\n",
        "offset = 256\n",
        "for key in dictByHugoMax50:\n",
        "  dic5[key] = convertToNineBits(convertToBinary(offset + i))\n",
        "  offset += 1\n",
        "\n",
        "print(dic5)\n",
        "\n",
        "reverted_dic = {v: k for k, v in dic.items()}\n",
        "reverted_dic2 = {v: k for k, v in dic2.items()}\n",
        "reverted_dic3 = {v: k for k, v in dic3.items()}\n",
        "reverted_dic4 = {v: k for k, v in dic4.items()}\n",
        "reverted_dic5 = {v: k for k, v in dic5.items()}\n",
        "\n",
        "print(reverted_dic5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awJCxj_ArQG9",
        "outputId": "39dcaa14-18c1-4d17-a771-a6b1da5b1156"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'  ': '100000000', 'e ': '100000001', 's ': '100000010', 't ': '100000011', ' d': '100000100', ', ': '100000101', 'ai': '100000110', 'es': '100000111', ' l': '100001000', 'le': '100001001', 'en': '100001010', 're': '100001011', 'ou': '100001100', 'de': '100001101', ' s': '100001110', 'nt': '100001111', 'it': '100010000', ' p': '100010001', 'on': '100010010', ' c': '100010011', 'an': '100010100', 'n ': '100010101', ' e': '100010110', 'ur': '100010111', 'te': '100011000', 'er': '100011001', 'is': '100011010', 'r ': '100011011', '\\n ': '100011100', ' a': '100011101', '\\n\\n': '100011110', 'a ': '100011111', 'qu': '100100000', '   ': '100100001', 'se': '100100010', 'ne': '100100011', 'et': '100100100', ' m': '100100101', 'me': '100100110', 'la': '100100111', ' de': '100101000', 'ie': '100101001', 'il': '100101010', 'e  ': '100101011', 'eu': '100101100', ' t': '100101101', 'ra': '100101110', 'ar': '100101111', 'in': '100110000', 'll': '100110001', 'ui': '100110010', 'l ': '100110011', 'es ': '100110100', 'un': '100110101', '. ': '100110110', '\\n  ': '100110111', ' f': '100111000', 'us': '100111001', '\\n\\n ': '100111010', '\\n\\n\\n': '100111011', 'co': '100111100', ' q': '100111101', ' r': '100111110', ' v': '100111111', 'tr': '101000000', 'pa': '101000001', 'ns': '101000010', 'ue': '101000011', 'it ': '101000100', 'oi': '101000101', 'ait': '101000110', 'e,': '101000111', '    ': '101001000', 'ce': '101001001', 'sa': '101001010', 'de ': '101001011', 've': '101001100', 'le ': '101001101', 'i ': '101001110', 'ta': '101001111', 'ut': '101010000', 'ri': '101010001', 'au': '101010010', 'u ': '101010011', 'ch': '101010100', 'em': '101010101', 'nd': '101010110', 's  ': '101010111', 'ti': '101011000', 'ir': '101011001', ' le': '101011010', '\\n   ': '101011011', 'ent': '101011100', 'ma': '101011101', 'ro': '101011110', '\\n\\n  ': '101011111', 'so': '101100000', 'po': '101100001', '\\n\\n\\n ': '101100010', ' u': '101100011', 'nt ': '101100100', 'el': '101100101', 't  ': '101100110', ' n': '101100111', 'or': '101101000', 'ss': '101101001', ' i': '101101010', ' b': '101101011', 's,': '101101100', ' qu': '101101101', '  d': '101101110', '.\\n': '101101111', 'om': '101110000', \"'a\": '101110001', 'av': '101110010', 'as': '101110011', 'vo': '101110100', 'va': '101110101', '\\n    ': '101110110', 'à ': '101110111', 'st': '101111000', '\\n\\n   ': '101111001', '\\n\\n\\n  ': '101111010', 'lle': '101111011', 'e.': '101111100', 'pr': '101111101', 'to': '101111110', '«\\xa0': '101111111', ' à': '110000000', ' j': '110000001', 'ne ': '110000010', 'da': '110000011', ' «': '110000100', '\\xa0»': '110000101', 'e, ': '110000110', ' de ': '110000111', ',  ': '110001000', 'al': '110001001', 'lu': '110001010', 'si': '110001011', 'ant': '110001100', ' et': '110001101', 'et ': '110001110', 'mm': '110001111', 'pe': '110010000', '\\xa0:': '110010001', 'ait ': '110010010', 'e\\n': '110010011', ' la': '110010100', '  l': '110010101', 'mo': '110010110', '\\n\\n    ': '110010111', '\\n\\n\\n   ': '110011000', ' pa': '110011001', ' un': '110011010', 'la ': '110011011', 't,': '110011100', 'di': '110011101', \"l'\": '110011110', 'he': '110011111', 'Il': '110100000', 'our': '110100001', '»\\n': '110100010', 'rt': '110100011', \"d'\": '110100100', 'que': '110100101', ' se': '110100110', 're ': '110100111', \"'e\": '110101000', ' I': '110101001', ' co': '110101010', 'na': '110101011', 'ux': '110101100', '\\n\\n\\n    ': '110101101', '.\\xa0': '110101110', 's, ': '110101111', 'e d': '110110000', 'ré': '110110001', 'nc': '110110010', 'rs': '110110011', 'ais': '110110100', 'les': '110110101', 'is ': '110110110', 'mi': '110110111', 's.': '110111000', '  s': '110111001', 'il ': '110111010', 'ge': '110111011', 'on ': '110111100', 'li': '110111101', 'su': '110111110', 'ét': '110111111', 'ur ': '111000000', 'fa': '111000001', '  p': '111000010', 'at': '111000011', '.\\n\\n': '111000100', ' g': '111000101', ' «\\xa0': '111000110', ' E': '111000111', ' so': '111001000', ':\\n': '111001001', ' en': '111001010', 'er ': '111001011', 'vi': '111001100', 'ous': '111001101', 'ns ': '111001110', 'us ': '111001111', 'ien': '111010000', ' à ': '111010001', 'e s': '111010010', 'ec': '111010011', ' et ': '111010100', 'ha': '111010101', 'tt': '111010110', 'e\\xa0': '111010111', 'x ': '111011000', 's\\n': '111011001', '  c': '111011010', 'ée': '111011011', ' é': '111011100', 'é ': '111011101', 'une': '111011110', 'en ': '111011111', ' po': '111100000', 'un ': '111100001', \"u'\": '111100010', 'pl': '111100011', 'e l': '111100100', ' il': '111100101', '  e': '111100110', 'mme': '111100111', 'n  ': '111101000', ' o': '111101001', ' la ': '111101010', 'no': '111101011', 'te ': '111101100', 'uv': '111101101', 'ue ': '111101110', 'nn': '111101111', 'me ': '111110000', ' re': '111110001', 'je': '111110010', 'tre': '111110011', 'bl': '111110100', '\\xa0»\\n': '111110101', 'du': '111110110', '»\\n\\n': '111110111', 't d': '111111000', '  «': '111111001', 't, ': '111111010', 'lo': '111111011', 'eur': '111111100', 'ui ': '111111101', ' Il': '111111110', ' vo': '111111111'}\n",
            "{'100000000': '  ', '100000001': 'e ', '100000010': 's ', '100000011': 't ', '100000100': ' d', '100000101': ', ', '100000110': 'ai', '100000111': 'es', '100001000': ' l', '100001001': 'le', '100001010': 'en', '100001011': 're', '100001100': 'ou', '100001101': 'de', '100001110': ' s', '100001111': 'nt', '100010000': 'it', '100010001': ' p', '100010010': 'on', '100010011': ' c', '100010100': 'an', '100010101': 'n ', '100010110': ' e', '100010111': 'ur', '100011000': 'te', '100011001': 'er', '100011010': 'is', '100011011': 'r ', '100011100': '\\n ', '100011101': ' a', '100011110': '\\n\\n', '100011111': 'a ', '100100000': 'qu', '100100001': '   ', '100100010': 'se', '100100011': 'ne', '100100100': 'et', '100100101': ' m', '100100110': 'me', '100100111': 'la', '100101000': ' de', '100101001': 'ie', '100101010': 'il', '100101011': 'e  ', '100101100': 'eu', '100101101': ' t', '100101110': 'ra', '100101111': 'ar', '100110000': 'in', '100110001': 'll', '100110010': 'ui', '100110011': 'l ', '100110100': 'es ', '100110101': 'un', '100110110': '. ', '100110111': '\\n  ', '100111000': ' f', '100111001': 'us', '100111010': '\\n\\n ', '100111011': '\\n\\n\\n', '100111100': 'co', '100111101': ' q', '100111110': ' r', '100111111': ' v', '101000000': 'tr', '101000001': 'pa', '101000010': 'ns', '101000011': 'ue', '101000100': 'it ', '101000101': 'oi', '101000110': 'ait', '101000111': 'e,', '101001000': '    ', '101001001': 'ce', '101001010': 'sa', '101001011': 'de ', '101001100': 've', '101001101': 'le ', '101001110': 'i ', '101001111': 'ta', '101010000': 'ut', '101010001': 'ri', '101010010': 'au', '101010011': 'u ', '101010100': 'ch', '101010101': 'em', '101010110': 'nd', '101010111': 's  ', '101011000': 'ti', '101011001': 'ir', '101011010': ' le', '101011011': '\\n   ', '101011100': 'ent', '101011101': 'ma', '101011110': 'ro', '101011111': '\\n\\n  ', '101100000': 'so', '101100001': 'po', '101100010': '\\n\\n\\n ', '101100011': ' u', '101100100': 'nt ', '101100101': 'el', '101100110': 't  ', '101100111': ' n', '101101000': 'or', '101101001': 'ss', '101101010': ' i', '101101011': ' b', '101101100': 's,', '101101101': ' qu', '101101110': '  d', '101101111': '.\\n', '101110000': 'om', '101110001': \"'a\", '101110010': 'av', '101110011': 'as', '101110100': 'vo', '101110101': 'va', '101110110': '\\n    ', '101110111': 'à ', '101111000': 'st', '101111001': '\\n\\n   ', '101111010': '\\n\\n\\n  ', '101111011': 'lle', '101111100': 'e.', '101111101': 'pr', '101111110': 'to', '101111111': '«\\xa0', '110000000': ' à', '110000001': ' j', '110000010': 'ne ', '110000011': 'da', '110000100': ' «', '110000101': '\\xa0»', '110000110': 'e, ', '110000111': ' de ', '110001000': ',  ', '110001001': 'al', '110001010': 'lu', '110001011': 'si', '110001100': 'ant', '110001101': ' et', '110001110': 'et ', '110001111': 'mm', '110010000': 'pe', '110010001': '\\xa0:', '110010010': 'ait ', '110010011': 'e\\n', '110010100': ' la', '110010101': '  l', '110010110': 'mo', '110010111': '\\n\\n    ', '110011000': '\\n\\n\\n   ', '110011001': ' pa', '110011010': ' un', '110011011': 'la ', '110011100': 't,', '110011101': 'di', '110011110': \"l'\", '110011111': 'he', '110100000': 'Il', '110100001': 'our', '110100010': '»\\n', '110100011': 'rt', '110100100': \"d'\", '110100101': 'que', '110100110': ' se', '110100111': 're ', '110101000': \"'e\", '110101001': ' I', '110101010': ' co', '110101011': 'na', '110101100': 'ux', '110101101': '\\n\\n\\n    ', '110101110': '.\\xa0', '110101111': 's, ', '110110000': 'e d', '110110001': 'ré', '110110010': 'nc', '110110011': 'rs', '110110100': 'ais', '110110101': 'les', '110110110': 'is ', '110110111': 'mi', '110111000': 's.', '110111001': '  s', '110111010': 'il ', '110111011': 'ge', '110111100': 'on ', '110111101': 'li', '110111110': 'su', '110111111': 'ét', '111000000': 'ur ', '111000001': 'fa', '111000010': '  p', '111000011': 'at', '111000100': '.\\n\\n', '111000101': ' g', '111000110': ' «\\xa0', '111000111': ' E', '111001000': ' so', '111001001': ':\\n', '111001010': ' en', '111001011': 'er ', '111001100': 'vi', '111001101': 'ous', '111001110': 'ns ', '111001111': 'us ', '111010000': 'ien', '111010001': ' à ', '111010010': 'e s', '111010011': 'ec', '111010100': ' et ', '111010101': 'ha', '111010110': 'tt', '111010111': 'e\\xa0', '111011000': 'x ', '111011001': 's\\n', '111011010': '  c', '111011011': 'ée', '111011100': ' é', '111011101': 'é ', '111011110': 'une', '111011111': 'en ', '111100000': ' po', '111100001': 'un ', '111100010': \"u'\", '111100011': 'pl', '111100100': 'e l', '111100101': ' il', '111100110': '  e', '111100111': 'mme', '111101000': 'n  ', '111101001': ' o', '111101010': ' la ', '111101011': 'no', '111101100': 'te ', '111101101': 'uv', '111101110': 'ue ', '111101111': 'nn', '111110000': 'me ', '111110001': ' re', '111110010': 'je', '111110011': 'tre', '111110100': 'bl', '111110101': '\\xa0»\\n', '111110110': 'du', '111110111': '»\\n\\n', '111111000': 't d', '111111001': '  «', '111111010': 't, ', '111111011': 'lo', '111111100': 'eur', '111111101': 'ui ', '111111110': ' Il', '111111111': ' vo'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class to build a tree defining all the possible  string in dic\n",
        "class SuffixTree():\n",
        "  class Node():\n",
        "    def __init__(self,char):\n",
        "      self.char = char\n",
        "      self.out = {}\n",
        "      self.isFinal = False\n",
        "    def __str__(self, level=0):\n",
        "      ret = \"  \" * level + str(self.char) + \"\\n\"\n",
        "      for c in self.out:\n",
        "        ret += self.out[c].__str__(level + 1)\n",
        "      return ret\n",
        "\n",
        "  def __init__(self, dic):\n",
        "    self.root = self.Node(None)\n",
        "    self.root.isFinal = True\n",
        "    for key in dic:\n",
        "      cursor = self.root\n",
        "      for c in key:\n",
        "        if c in cursor.out:\n",
        "          cursor = cursor.out[c]\n",
        "        else:\n",
        "          node = self.Node(c)\n",
        "          cursor.out[c] = node\n",
        "          cursor = node\n",
        "      cursor.isFinal = True\n",
        "  def longestPrefix(self, s):\n",
        "    cursor = self.root\n",
        "    word = ''\n",
        "    temp = ''\n",
        "    end = False\n",
        "    i = 0\n",
        "    length = len(s)\n",
        "    while not(end) and i < length:\n",
        "      if s[i] in cursor.out:\n",
        "        temp = temp + s[i]\n",
        "        cursor = cursor.out[s[i]]\n",
        "        if cursor.isFinal:\n",
        "          word = temp\n",
        "        i += 1\n",
        "      else:\n",
        "        end = True\n",
        "    return word\n",
        "  def __str__(self):\n",
        "    return f'{self.root}'\n",
        "\n",
        "s = SuffixTree({'ab' : 1, 'abc': 2, 'coucou' : 5, 'aba' : 4, 'aaa' : 8})\n",
        "print(s)\n",
        "s.longestPrefix('abdc')\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "ND_fSFhFq51O",
        "outputId": "598aa300-55b6-4692-a919-178281425db6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "  a\n",
            "    b\n",
            "      c\n",
            "      a\n",
            "    a\n",
            "      a\n",
            "  c\n",
            "    o\n",
            "      u\n",
            "        c\n",
            "          o\n",
            "            u\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ab'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree = SuffixTree(dic)\n",
        "tree2 = SuffixTree(dic2)\n",
        "tree3 = SuffixTree(dic3)\n",
        "tree4 = SuffixTree(dic4)\n",
        "tree5 = SuffixTree(dic5)"
      ],
      "metadata": {
        "id": "FgOeftRxAILs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compress(string, tree, dic):\n",
        "  i = 0\n",
        "  ret = ''\n",
        "  while i<len(string):\n",
        "    temp = tree.longestPrefix(string[i:])\n",
        "    n = len(temp)\n",
        "    if n == 0:\n",
        "      bit = convertToNineBits(convertToBinary(ord(string[i])))\n",
        "      ret += bit\n",
        "      i += 1\n",
        "    else:\n",
        "      bit = dic[temp]\n",
        "      ret += bit\n",
        "      i += n\n",
        "  return ret\n",
        "\n",
        "\n",
        "\n",
        "def decompress(string, dic):\n",
        "  ret = ''\n",
        "  for i in range(0, len(string) - 1, 9):\n",
        "    if int(string[i : i + 9], 2) > 255:\n",
        "      ret += dic[string[i : i + 9]]\n",
        "    else:\n",
        "      ret += chr(int(string[i : i + 9], 2))\n",
        "  return ret"
      ],
      "metadata": {
        "id": "d22Anv76pQBY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tests sur la base d'apprentissage du dictionnaire**"
      ],
      "metadata": {
        "id": "XsyVEn-ZfJWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First dictionnary not based on a book\n",
        "\n",
        "compressed = compress(text, tree, dic)\n",
        "\n",
        "decompressed = decompress(compressed, reverted_dic)\n",
        "\n",
        "\n",
        "print(f'Le fichier avant décompression faisait {len(text) * 8} bits et celui compressé fait {len(compressed)} bits')\n",
        "print(f'Le taux de compression est donc de {len(compressed) / (len(text) * 8)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y394yPYxZrGi",
        "outputId": "0f2464a2-da20-42d9-e718-f9ee1a70cfcc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier avant décompression faisait 5442960 bits et celui compressé fait 5360544 bits\n",
            "Le taux de compression est donc de 0.9848582388994224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second dictionnary (made with only strings of 3 char)\n",
        "\n",
        "compressed2 = compress(text, tree2, dic2)\n",
        "\n",
        "decompressed2 = decompress(compressed2, reverted_dic2)\n",
        "\n",
        "\n",
        "print(f'Le fichier avant décompression faisait {len(text) * 8} bits et celui compressé fait {len(compressed2)} bits')\n",
        "print(f'Le taux de compression est donc de {len(compressed2) / (len(text) * 8)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wntOWF28ZyVg",
        "outputId": "42ba0094-839e-4637-e721-3c5da108e815"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier avant décompression faisait 5442960 bits et celui compressé fait 3422448 bits\n",
            "Le taux de compression est donc de 0.6287843379337713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Third dictionnary (made with strings of 2-3 char)\n",
        "\n",
        "compressed3 = compress(text, tree3, dic3)\n",
        "\n",
        "decompressed3 = decompress(compressed3, reverted_dic3)\n",
        "\n",
        "\n",
        "print(f'Le fichier avant décompression faisait {len(text) * 8} bits et celui compressé fait {len(compressed3)} bits')\n",
        "print(f'Le taux de compression est donc de {len(compressed3) / (len(text) * 8)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_g1-f2Yk27Z",
        "outputId": "a93d54d2-95da-4347-abe9-aeffdd273c46"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier avant décompression faisait 5442960 bits et celui compressé fait 3052683 bits\n",
            "Le taux de compression est donc de 0.5608497949645046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fourth dictionnary (made with only strings of 2-9 char)\n",
        "\n",
        "compressed4 = compress(text, tree4, dic4)\n",
        "\n",
        "decompressed4 = decompress(compressed4, reverted_dic4)\n",
        "\n",
        "\n",
        "print(f'Le fichier avant décompression faisait {len(text) * 8} bits et celui compressé fait {len(compressed4)} bits')\n",
        "print(f'Le taux de compression est donc de {len(compressed4) / (len(text) * 8)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175bf8c1-865c-4201-8131-e7007e60133f",
        "id": "q-cJTpd9Rdn5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier avant décompression faisait 5442960 bits et celui compressé fait 3031308 bits\n",
            "Le taux de compression est donc de 0.5569227038229199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fifth dictionnary (made with only strings of 2-49 char)\n",
        "\n",
        "compressed5 = compress(text, tree5, dic5)\n",
        "\n",
        "decompressed5 = decompress(compressed5, reverted_dic5)\n",
        "\n",
        "\n",
        "print(f'Le fichier avant décompression faisait {len(text) * 8} bits et celui compressé fait {len(compressed5)} bits')\n",
        "print(f'Le taux de compression est donc de {len(compressed5) / (len(text) * 8)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c9adf5-097c-4e22-f846-7c90dac799e2",
        "id": "M4mWLXmVReFY"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier avant décompression faisait 5442960 bits et celui compressé fait 3031308 bits\n",
            "Le taux de compression est donc de 0.5569227038229199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test du dictionnaire sur un autre livre, ici le premier tome du livre \"Les misérables\"**"
      ],
      "metadata": {
        "id": "njuNcCPPTnWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textract\n",
        "text2 = textract.process(\"dataFrenchWords/hugo_les_miserables_fantine_source.doc\")\n",
        "text2 = text2.decode(\"utf-8\")\n",
        "text2 = text2.replace('’', '\\'').replace('–', '-').replace('…', '...').replace('‘', '\\'').replace('€', 'euros').replace('[pic]', '')"
      ],
      "metadata": {
        "id": "d3sqDrKnUFrb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compressed6 = compress(text2, tree5, dic5)\n",
        "\n",
        "decompressed6 = decompress(compressed6, reverted_dic5)\n",
        "\n",
        "\n",
        "print(f'Le fichier avant décompression faisait {len(text2) * 8} bits et celui compressé fait {len(compressed6)} bits')\n",
        "print(f'Le taux de compression est donc de {len(compressed6) / (len(text2) * 8)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItGmxIkvUMIn",
        "outputId": "e7a3dd7f-e517-465d-9030-ea72a54c4265"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le fichier avant décompression faisait 6131592 bits et celui compressé fait 3502737 bits\n",
            "Le taux de compression est donc de 0.5712606122520872\n"
          ]
        }
      ]
    }
  ]
}